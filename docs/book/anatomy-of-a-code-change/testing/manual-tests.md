Manual tests

The feasibility of automated tests has its limits. The following product aspects are best evaluated with human judgement.

- Quality of output - "While technically correct, this is useless to me in this situation."
- Exploration - "I'm curious to see how this behaves if I combine these things."
- User Experience - "I mean it works... but I would not use this in my spare time."
- Accessability -  "I have achromatic vision and these colors look identical to me."
- Transparency - "I was playing around with it for a couple minutes and now have no idea how to get back."
- Breaking it - "I bet the dev forgot these things can interact with each other if I load them differently."

We can automate supporting processes for manual testing, e.g. we can statically analyse if every image on a webpage has an alt text, but it becomes unpractical to analyse if the alt text correctly describes the image. The same with design systems. We can statically verify our system is 

Automated testing is not suitable for all testing tasks. For example testing the quality of search results often involves human judgement. Creative explorative testing. UX expected result testing. Trying to break it.

There are certain aesthetic tasks we can test automatically. Do the loaded fonts correlate with the design system. Are buttons loaded with correct colors and hover animations?

Enforcing an established design system is 

Aestethic improvements, user experience, transparency, clicks to purchase.

